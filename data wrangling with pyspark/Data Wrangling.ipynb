{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Spark\n",
    "\n",
    "This is the code used in the previous screencast. Run each code cell to understand what the code does and how it works.\n",
    "\n",
    "These first three cells import libraries, instantiate a SparkSession, and then read in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, to_timestamp, to_date, isnan, when, count, col\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Wrangling Data\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"titanic.json\"\n",
    "df = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration \n",
    "\n",
    "The next cells explore the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Age=22.0, Cabin=None, Embarked='S', Fare=7.25, Name='Braund, Mr. Owen Harris', Parch=0, PassengerId=1, Pclass=3, Sex='male', SibSp=1, Survived=0, Ticket='A/5 21171'),\n",
       " Row(Age=38.0, Cabin='C85', Embarked='C', Fare=71.2833, Name='Cumings, Mrs. John Bradley (Florence Briggs Thayer)', Parch=0, PassengerId=2, Pclass=1, Sex='female', SibSp=1, Survived=1, Ticket='PC 17599'),\n",
       " Row(Age=26.0, Cabin=None, Embarked='S', Fare=7.925, Name='Heikkinen, Miss. Laina', Parch=0, PassengerId=3, Pclass=3, Sex='female', SibSp=0, Survived=1, Ticket='STON/O2. 3101282'),\n",
       " Row(Age=35.0, Cabin='C123', Embarked='S', Fare=53.1, Name='Futrelle, Mrs. Jacques Heath (Lily May Peel)', Parch=0, PassengerId=4, Pclass=1, Sex='female', SibSp=1, Survived=1, Ticket='113803'),\n",
       " Row(Age=35.0, Cabin=None, Embarked='S', Fare=8.05, Name='Allen, Mr. William Henry', Parch=0, PassengerId=5, Pclass=3, Sex='male', SibSp=0, Survived=0, Ticket='373450')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the first 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Parch: long (nullable = true)\n",
      " |-- PassengerId: long (nullable = true)\n",
      " |-- Pclass: long (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- SibSp: long (nullable = true)\n",
      " |-- Survived: long (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## check the dataframe attributes\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----+--------+-----------------+--------------------+-------------------+-----------------+------------------+------+------------------+-------------------+------------------+\n",
      "|summary|               Age|Cabin|Embarked|             Fare|                Name|              Parch|      PassengerId|            Pclass|   Sex|             SibSp|           Survived|            Ticket|\n",
      "+-------+------------------+-----+--------+-----------------+--------------------+-------------------+-----------------+------------------+------+------------------+-------------------+------------------+\n",
      "|  count|               714|  204|     889|              891|                 891|                891|              891|               891|   891|               891|                891|               891|\n",
      "|   mean| 29.69911764705882| null|    null| 32.2042079685746|                null|0.38159371492704824|            446.0| 2.308641975308642|  null|0.5230078563411896| 0.3838383838383838|260318.54916792738|\n",
      "| stddev|14.526497332334035| null|    null|49.69342859718089|                null| 0.8060572211299488|257.3538420152301|0.8360712409770491|  null|1.1027434322934315|0.48659245426485753|471609.26868834975|\n",
      "|    min|              0.42|  A10|       C|              0.0| Abbing, Mr. Anthony|                  0|                1|                 1|female|                 0|                  0|            110152|\n",
      "|    max|              80.0|    T|       S|         512.3292|van Melkebeke, Mr...|                  6|              891|                 3|  male|                 8|                  1|         WE/P 5735|\n",
      "+-------+------------------+-----+--------+-----------------+--------------------+-------------------+-----------------+------------------+------+------------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Get dataframe columns statistics\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               Age|\n",
      "+-------+------------------+\n",
      "|  count|               714|\n",
      "|   mean| 29.69911764705882|\n",
      "| stddev|14.526497332334035|\n",
      "|    min|              0.42|\n",
      "|    max|              80.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## check the Age statistics\n",
    "df.describe(\"Age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the number of rows\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the number of columns\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Parch|\n",
      "+-----+\n",
      "|    0|\n",
      "|    1|\n",
      "|    2|\n",
      "|    3|\n",
      "|    4|\n",
      "|    5|\n",
      "|    6|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Get unique Parch values using dropDuplicates()\n",
    "df.select(\"Parch\").dropDuplicates().sort(\"Parch\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Parch|\n",
      "+-----+\n",
      "|    0|\n",
      "|    1|\n",
      "|    2|\n",
      "|    3|\n",
      "|    4|\n",
      "|    5|\n",
      "|    6|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Parch').distinct().sort('Parch').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Parch|\n",
      "+-----+\n",
      "|    0|\n",
      "|    1|\n",
      "|    2|\n",
      "|    3|\n",
      "|    4|\n",
      "|    5|\n",
      "|    6|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## get unique Parch values using distinct()\n",
    "df.select('Parch').distinct().sort('Parch').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Braund, Mr. Owen Harris', Age=22.0, Pclass=3, Sex='male', Survived=0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## select details based on some condition using where\n",
    "df.select([\"Name\", \"Age\", \"Pclass\", \"Sex\", \"Survived\"]).where(df.PassengerId == \"1\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Braund, Mr. Owen Harris', Age=22.0, Pclass=3, Sex='male', Survived=0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## select details based on some condition using filter\n",
    "df.select([\"Name\", \"Age\", \"Pclass\", \"Sex\", \"Survived\"]).filter(df.PassengerId == \"1\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use of functions as udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prefix = udf(lambda x: x.split(',')[1].strip(\" \").split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the name prefix of each passenger and store the prefix values in NamePrefix column\n",
    "df = df.withColumn(\"NamePrefix\", get_prefix(df.Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Age=22.0, Cabin=None, Embarked='S', Fare=7.25, Name='Braund, Mr. Owen Harris', Parch=0, PassengerId=1, Pclass=3, Sex='male', SibSp=1, Survived=0, Ticket='A/5 21171', NamePrefix='Mr.'),\n",
       " Row(Age=38.0, Cabin='C85', Embarked='C', Fare=71.2833, Name='Cumings, Mrs. John Bradley (Florence Briggs Thayer)', Parch=0, PassengerId=2, Pclass=1, Sex='female', SibSp=1, Survived=1, Ticket='PC 17599', NamePrefix='Mrs.'),\n",
       " Row(Age=26.0, Cabin=None, Embarked='S', Fare=7.925, Name='Heikkinen, Miss. Laina', Parch=0, PassengerId=3, Pclass=3, Sex='female', SibSp=0, Survived=1, Ticket='STON/O2. 3101282', NamePrefix='Miss.'),\n",
       " Row(Age=35.0, Cabin='C123', Embarked='S', Fare=53.1, Name='Futrelle, Mrs. Jacques Heath (Lily May Peel)', Parch=0, PassengerId=4, Pclass=1, Sex='female', SibSp=1, Survived=1, Ticket='113803', NamePrefix='Mrs.'),\n",
       " Row(Age=35.0, Cabin=None, Embarked='S', Fare=8.05, Name='Allen, Mr. William Henry', Parch=0, PassengerId=5, Pclass=3, Sex='male', SibSp=0, Survived=0, Ticket='373450', NamePrefix='Mr.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## As you can see Name Prefix column is added\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some statistics using Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check how many passengers survived based on their name prefix\n",
    "name_prefix_survived = df.filter(df.Survived == \"1\").groupby(df.NamePrefix).count().orderBy(desc('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|NamePrefix|count|\n",
      "+----------+-----+\n",
      "|     Miss.|  127|\n",
      "|      Mrs.|   99|\n",
      "|       Mr.|   81|\n",
      "|   Master.|   23|\n",
      "|       Dr.|    3|\n",
      "|     Mlle.|    2|\n",
      "|       Ms.|    1|\n",
      "|    Major.|    1|\n",
      "|      Sir.|    1|\n",
      "|      Col.|    1|\n",
      "|      Mme.|    1|\n",
      "|       the|    1|\n",
      "|     Lady.|    1|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name_prefix_survived.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Rows with Missing Values\n",
    "\n",
    "As you'll see, it turns out there are some missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------+----+----+-----+-----------+------+---+-----+--------+------+----------+\n",
      "|Age|Cabin|Embarked|Fare|Name|Parch|PassengerId|Pclass|Sex|SibSp|Survived|Ticket|NamePrefix|\n",
      "+---+-----+--------+----+----+-----+-----------+------+---+-----+--------+------+----------+\n",
      "|177|  687|       2|   0|   0|    0|          0|     0|  0|    0|       0|     0|         0|\n",
      "+---+-----+--------+----+----+-----+-----------+------+---+-----+--------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Check Null values in each column\n",
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check Null values in Age column\n",
    "len(df.where(col(\"Age\").isNull()).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = df.dropna(how = \"any\", subset = [\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## It dropped around 177 rows\n",
    "df_valid.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Window function\n",
    "\n",
    "Use a window function and cumulative sum to distinguish each user's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Created some dummy data to apply Window function\n",
    "user_log = spark.read.csv(\"data_for_window.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+\n",
      "| id|    start|some_value|\n",
      "+---+---------+----------+\n",
      "|  1| 1/1/2015|        20|\n",
      "|  1| 1/6/2015|        10|\n",
      "|  1| 1/7/2015|        25|\n",
      "|  1|1/12/2015|        30|\n",
      "|  2| 1/1/2015|         5|\n",
      "|  2| 1/3/2015|        30|\n",
      "|  2| 2/1/2015|        20|\n",
      "+---+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_log.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- start: string (nullable = true)\n",
      " |-- some_value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_log.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see start column which contains dates is of type string so we need to first convert it to date type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+-----------+\n",
      "| id|    start|some_value|start_dates|\n",
      "+---+---------+----------+-----------+\n",
      "|  1| 1/1/2015|        20| 2015-01-01|\n",
      "|  1| 1/6/2015|        10| 2015-01-06|\n",
      "|  1| 1/7/2015|        25| 2015-01-07|\n",
      "|  1|1/12/2015|        30| 2015-01-12|\n",
      "|  2| 1/1/2015|         5| 2015-01-01|\n",
      "|  2| 1/3/2015|        30| 2015-01-03|\n",
      "|  2| 2/1/2015|        20| 2015-01-01|\n",
      "+---+---------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_log = user_log.withColumn(\"start_dates\",to_date(user_log.start, 'mm/dd/yyyy'))\n",
    "user_log.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- start: string (nullable = true)\n",
      " |-- some_value: string (nullable = true)\n",
      " |-- start_dates: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# as you can see start_dates is a column of type Date\n",
    "user_log.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a window object for each id i.e. any function we apply over window such as mean or sum, that will apply on each id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowval = Window.partitionBy(\"id\").orderBy(desc(\"start_dates\")).rangeBetween(Window.unboundedPreceding, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_log_valid = user_log.withColumn(\"range_sum\", Fsum(\"some_value\").over(windowval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, range sum column is having the cumulative sum of some_value for each id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+-----------+---------+\n",
      "| id|    start|some_value|start_dates|range_sum|\n",
      "+---+---------+----------+-----------+---------+\n",
      "|  1|1/12/2015|        30| 2015-01-12|     30.0|\n",
      "|  1| 1/7/2015|        25| 2015-01-07|     55.0|\n",
      "|  1| 1/6/2015|        10| 2015-01-06|     65.0|\n",
      "|  1| 1/1/2015|        20| 2015-01-01|     85.0|\n",
      "|  2| 1/3/2015|        30| 2015-01-03|     30.0|\n",
      "|  2| 1/1/2015|         5| 2015-01-01|     55.0|\n",
      "|  2| 2/1/2015|        20| 2015-01-01|     55.0|\n",
      "+---+---------+----------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_log_valid.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
